{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLY USE THIS FILE IF TRANSFER LEARNING TENSOR IS RAN PRIOR\n",
    "    Load the 3 saved torch files. Can train directly from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.1' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the datasets\n",
    "train_set = torch.load('Btrain_set.pt')\n",
    "validation_set = torch.load('Bvalidation_set.pt')\n",
    "test_set = torch.load('Btest_set.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "class preLearnedFungaV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(preLearnedFungaV1, self).__init__()\n",
    "        self.name = \"fungaV1\"\n",
    "        #added anther convolution channel before fc layers\n",
    "        self.conv1 = nn.Conv2d(256, 128, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(128*6*6, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, n)\n",
    "\n",
    "        #dropout implementation\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        #FC layers\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.squeeze(1)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoadFunction(BatchSize):\n",
    "  train_load = torch.utils.data.DataLoader(train_set, batch_size = BatchSize, shuffle=True)\n",
    "  validation_load = torch.utils.data.DataLoader(validation_set, batch_size = BatchSize)\n",
    "  testing_load = torch.utils.data.DataLoader(test_set, batch_size = BatchSize)\n",
    "  return train_load, validation_load, testing_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidationLoss(net, validation_loader, criterion):\n",
    "  totalLoss = 0\n",
    "  count = 0\n",
    "  for data in validation_loader:\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    totalLoss += loss.item()\n",
    "    count += inputs.size(0)\n",
    "  totalLoss = totalLoss / count\n",
    "  return totalLoss\n",
    "\n",
    "\n",
    "#model name\n",
    "def get_model_name(name, batch_size, lr, epoch):\n",
    "    path = \"modelStorage/model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, lr, epoch)\n",
    "    return path\n",
    "\n",
    "#plotting helper function\n",
    "import matplotlib.pyplot as plt\n",
    "#plot image function\n",
    "#modified from lab 2\n",
    "def plot_training_curve(path):\n",
    "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
    "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
    "    n = len(train_loss)\n",
    "    #plot model\n",
    "    plt.title(\"Train vs Validation Loss\")\n",
    "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_net_TL(net, batchsize=24, learning_rate=0.007, num_epochs=12, weight_decay=0): #values here are defaults, should* be overwritten when called\n",
    "\n",
    "  torch.manual_seed(1)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.8, weight_decay = weight_decay)\n",
    "\n",
    "  training_loader, validation_loader, _ = dataLoadFunction(batchsize)\n",
    "\n",
    "  train_loss_graph = np.zeros(num_epochs)\n",
    "  val_loss_graph = np.zeros(num_epochs)\n",
    "\n",
    "  totalHere = 0\n",
    "  startTime = time.time()\n",
    "  for currepoch in range(num_epochs):\n",
    "    #print(\"New epoch\")\n",
    "    trainLoss = 0\n",
    "    net.train()\n",
    "    for i, (inputs, labels) in enumerate(training_loader):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      inputs = torch.tensor(inputs.detach().numpy()).to(inputs.device)\n",
    "      outputs = net(inputs)\n",
    "\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      trainLoss += loss.item()\n",
    "      totalHere += inputs.size(0)\n",
    "\n",
    "    #print(\"Onto validation\")\n",
    "    net.eval()\n",
    "    train_loss_graph[currepoch] = trainLoss/totalHere\n",
    "    val_loss_graph[currepoch] = getValidationLoss(net, validation_loader, criterion)\n",
    "    if (currepoch % 5 == 0):\n",
    "      print(f\"Epoch: {currepoch} Training Loss: {train_loss_graph[currepoch]:.6f}, Validation Loss: {val_loss_graph[currepoch]:.6f}, Time: {time.time() - startTime:.2f} seconds\")\n",
    "      model_path = get_model_name(net.name, batchsize, learning_rate, currepoch)\n",
    "      torch.save(net.state_dict(), model_path)\n",
    "      np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss_graph)\n",
    "      np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss_graph)\n",
    "  print(\"Total time: \", time.time()-startTime)\n",
    "\n",
    "  path = \"modelStorage/model_{0}_bs{1}_lr{2}_epoch{3}\".format(net.name, batchsize, learning_rate, num_epochs)\n",
    "  np.savetxt(\"{}_train_loss.csv\".format(path), train_loss_graph)\n",
    "  np.savetxt(\"{}_val_loss.csv\".format(path), val_loss_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variabls - so you don't have to modify them everywhere\n",
    "BATCH_SIZE = 36\n",
    "NUM_EPOCHS = 21\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "#With Weight Decay\n",
    "WEIGHTDECAY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3TL = preLearnedFungaV1()\n",
    "#train_net_TL(net3TL, batchsize=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "train_net_TL(net3TL, batchsize=BATCH_SIZE, num_epochs=NUM_EPOCHS, weight_decay = WEIGHTDECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curve(\"modelStorage/model_{0}_bs{1}_lr{2}_epoch{3}\".format(\"fungaV1\", BATCH_SIZE, LEARNING_RATE, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy function\n",
    "def getAccuracy(net, loader):\n",
    "  correct, count = 0, 0\n",
    "  net.eval()\n",
    "  #no gradient modification\n",
    "  with torch.no_grad():\n",
    "    print(\"Total number of batches: \", len(loader))\n",
    "    for currbatch, (i, corr) in enumerate(loader):\n",
    "      count += corr.shape[0]\n",
    "\n",
    "      correct += (torch.max(net(i), 1)[1] == corr).sum().item()\n",
    "\n",
    "  return correct / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestNet = preLearnedFungaV1()\n",
    "model_path = get_model_name(\"fungaV1\", batch_size=BATCH_SIZE, lr=LEARNING_RATE, epoch=(10))\n",
    "state = torch.load(model_path)\n",
    "bestNet.load_state_dict(state)\n",
    "\n",
    "_,_, testLoad = dataLoadFunction(24)\n",
    "\n",
    "dataLoad = testLoad\n",
    "\n",
    "accuracy = getAccuracy(bestNet, dataLoad)\n",
    "print(\"Test Classification Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
