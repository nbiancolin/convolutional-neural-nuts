{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE ONLY USED FOR PRESENTATION DEMO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eric7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\eric7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224,224))])\n",
    "import torchvision.models\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "import pickle \n",
    "with open('mapping.pkl', 'rb') as file:\n",
    "    mappingDict = pickle.load(file)\n",
    "\n",
    "class preLearnedFungaV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(preLearnedFungaV1, self).__init__()\n",
    "        self.name = \"fungaV1\"\n",
    "        #added anther convolution channel before fc layers\n",
    "        self.conv1 = nn.Conv2d(256, 128, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(128*6*6, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "        #dropout implementation\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        #FC layers\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.squeeze(1)  \n",
    "        return x\n",
    "def get_model_name(name, batch_size, lr, epoch):\n",
    "    path = \"modelStorage/model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, lr, epoch)\n",
    "    return path\n",
    "\n",
    "def useModel(image):\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.0006\n",
    "    BEST_EPOCH = 90\n",
    "    n = 10\n",
    "    bestNet = preLearnedFungaV1()\n",
    "    model_path = get_model_name(\"fungaV1\", batch_size=BATCH_SIZE, lr=LEARNING_RATE, epoch=BEST_EPOCH)\n",
    "    state = torch.load(model_path)\n",
    "    bestNet.load_state_dict(state)\n",
    "\n",
    "    featureExtraction = alexnet.features(transform(Image.open(image)))\n",
    "    bestNet.eval()\n",
    "    with torch.no_grad():\n",
    "        output = bestNet(featureExtraction.unsqueeze(0))\n",
    "    print(f\"\\n\\n{output}\")\n",
    "    modelPrediction = torch.max(output, 1)\n",
    "    print(\"\\n\\nModel Prediction:\")\n",
    "\n",
    "    return mappingDict[modelPrediction[1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tensor([[-1.2917,  3.6404,  5.0305,  0.9256,  6.5264, -0.8113, -2.7879, -3.1406,\n",
      "         -5.4782, -3.7038]])\n",
      "\n",
      "\n",
      "Model Prediction:\n",
      "Hygrocybe\n",
      "Successful prediction\n"
     ]
    }
   ],
   "source": [
    "KeyName = \"Hygrocybe\"\n",
    "img = \"DemoImg.png\"\n",
    "prediction = useModel(img)\n",
    "print(prediction)\n",
    "\n",
    "if KeyName == prediction:\n",
    "    print(\"Successful prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
