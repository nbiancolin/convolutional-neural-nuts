@misc{Drechsler-SantosKarstedtEtAl.MINDFunga.2023,
  title = {{{MIND}}.{{Funga}}},
  shorttitle = {{{MIND}}.{{Funga}}},
  author = {{Drechsler-Santos}, Elisandro Ricardo and Karstedt, Fernanda and Zimmermann Loureiro Chaves, Thiago and Titton, Mahatm{\=a} and {Martins da Cunha}, Kelmer and Leopoldo, Elo{\'i}sa and {Alves-Silva}, Genivaldo and Rezende, Diogo and Kossmann, Thiago and Gumboski, Emerson Luiz and {von Wangenheim}, Aldo},
  year = {2023},
  month = jul,
  publisher = {Mendeley Data},
  doi = {10.17632/sfrbdjvxcc.2},
  urldate = {2024-06-05}
}

@article{HollisterCaiEtAl.UsingComputerVision.2023,
  title = {Using Computer Vision to Identify Limpets from Their Shells: A Case Study Using Four Species from the {{Baja California}} Peninsula},
  author = {Hollister, Jack D. and Cai, Xiaohao and Horton, Tammy and Price, Benjamin W. and Zarzyczny, Karolina M. and Fenberg, Phillip B.},
  year = {2023},
  journal = {Frontiers in Marine Science},
  volume = {10},
  issn = {2296-7745},
  abstract = {The shell morphology of limpets can be cryptic and highly variable, within and between species. Therefore, the visual identification of species can be troublesome even for experts. Here, we demonstrate the capability of computer vision models as a new method to assist with identifications. We investigate the ability of computers to distinguish between four species and two genera of limpets from the Baja California peninsula (Mexico) from digital images of shells from both dorsal and ventral orientations. Overall, the models performed marginally better (97.9\%) than experts (97.5\%) when predicting the same set of images and did so 240x faster. Moreover, we utilised a heatmap system to both verify that models are focussing on the specimens and to view which features on the specimens the models used to distinguish between species and genera. We then enlisted the expertise of limpet ecologists specialised in identification of species from the Baja peninsula to comment on whether the heatmaps are indeed focusing on specific morphological features per species/genus. They confirm that in their opinion, the majority of the heatmaps appear to be highlighting areas and features of morphological importance for distinguishing between groups. Our findings reveal that the cutting-edge technology of computer vision holds tremendous potential in enhancing species identification techniques used by taxonomists and ecologists. Not only does it provide a complementary approach to traditional methods, but it also opens new avenues for exploring the biology and ecology of limpets in greater detail.}
}

@article{SchneiderTaylorEtAl.PresentFutureApproaches.2019,
  title = {Past, Present and Future Approaches Using Computer Vision for Animal Re-Identification from Camera Trap Data},
  author = {Schneider, Stefan and Taylor, Graham W. and Linquist, Stefan and Kremer, Stefan C.},
  year = {2019},
  month = apr,
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {4},
  pages = {461--470},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13133},
  urldate = {2024-06-05},
  abstract = {Abstract The ability of a researcher to re-identify (re-ID) an individual animal upon re-encounter is fundamental for addressing a broad range of questions in the study of ecosystem function, community and population dynamics and behavioural ecology. Tagging animals during mark and recapture studies is the most common method for reliable animal re-ID; however, camera traps are a desirable alternative, requiring less labour, much less intrusion and prolonged and continuous monitoring into an environment. Despite these advantages, the analyses of camera traps and video for re-ID by humans are criticized for their biases related to human judgement and inconsistencies between analyses. In this review, we describe a brief history of camera traps for re-ID, present a collection of computer vision feature engineering methodologies previously used for animal re-ID, provide an introduction to the underlying mechanisms of deep learning relevant to animal re-ID, highlight the success of deep learning methods for human re-ID, describe the few ecological studies currently utilizing deep learning for camera trap analyses and our predictions for near future methodologies based on the rapid development of deep learning methods. For decades, ecologists with expertise in computer vision have successfully utilized feature engineering to extract meaningful features from camera trap images to improve the statistical rigor of individual comparisons and remove human bias from their camera trap analyses. Recent years have witnessed the emergence of deep learning systems which have demonstrated the accurate re-ID of humans based on image and video data with near perfect accuracy. Despite this success, ecologists have yet to utilize these approaches for animal re-ID. By utilizing novel deep learning methods for object detection and similarity comparisons, ecologists can extract animals from an image/video data and train deep learning classifiers to re-ID animal individuals beyond the capabilities of a human observer. This methodology will allow ecologists with camera/video trap data to reidentify individuals that exit and re-enter the camera frame. Our expectation is that this is just the beginning of a major trend that could stand to revolutionize the analysis of camera trap data and, ultimately, our approach to animal ecology.},
  keywords = {animal reidentification,camera traps,computer vision,convolutional networks,deep learning,density estimation,monitoring,object detection}
}

@article{LuckingAimeEtAl.UnambiguousIdentificationFungi.2020,
  title = {Unambiguous Identification of Fungi: Where Do We Stand and How Accurate and Precise Is Fungal {{DNA}} Barcoding?},
  author = {L{\"u}cking, Robert and Aime, M. Catherine and Robbertse, Barbara and Miller, Andrew N. and Ariyawansa, Hiran A. and Aoki, Takayuki and Cardinali, Gianluigi and Crous, Pedro W. and Druzhinina, Irina S. and Geiser, David M. and Hawksworth, David L. and Hyde, Kevin D. and Irinyi, Laszlo and Jeewon, Rajesh and Johnston, Peter R. and Kirk, Paul M. and Malosso, Elaine and May, Tom W. and Meyer, Wieland and {\"O}pik, Maarja and Robert, Vincent and Stadler, Marc and Thines, Marco and Vu, Duong and Yurkov, Andrey M. and Zhang, Ning and Schoch, Conrad L.},
  year = {2020},
  month = jul,
  journal = {IMA Fungus},
  volume = {11},
  number = {1},
  pages = {14},
  issn = {2210-6359},
  doi = {10.1186/s43008-020-00033-z},
  abstract = {True fungi (Fungi) and fungus-like organisms (e.g. Mycetozoa, Oomycota) constitute the second largest group of organisms based on global richness estimates, with around 3 million predicted species. Compared to plants and animals, fungi have simple body plans with often morphologically and ecologically obscure structures. This poses challenges for accurate and precise identifications. Here we provide a conceptual framework for the identification of fungi, encouraging the approach of integrative (polyphasic) taxonomy for species delimitation, i.e. the combination of genealogy (phylogeny), phenotype (including autecology), and reproductive biology (when feasible). This allows objective evaluation of diagnostic characters, either phenotypic or molecular or both. Verification of identifications is crucial but often neglected. Because of clade-specific evolutionary histories, there is currently no single tool for the identification of fungi, although DNA barcoding using the internal transcribed spacer (ITS) remains a first diagnosis, particularly in metabarcoding studies. Secondary DNA barcodes are increasingly implemented for groups where ITS does not provide sufficient precision. Issues of pairwise sequence similarity-based identifications and OTU clustering are discussed, and multiple sequence alignment-based phylogenetic approaches with subsequent verification are recommended as more accurate alternatives. In metabarcoding approaches, the trade-off between speed and accuracy and precision of molecular identifications must be carefully considered. Intragenomic variation of the ITS and other barcoding markers should be properly documented, as phylotype diversity is not necessarily a proxy of species richness. Important strategies to improve molecular identification of fungi are: (1) broadly document intraspecific and intragenomic variation of barcoding markers; (2) substantially expand sequence repositories, focusing on undersampled clades and missing taxa; (3) improve curation of sequence labels in primary repositories and substantially increase the number of sequences based on verified material; (4) link sequence data to digital information of voucher specimens including imagery. In parallel, technological improvements to genome sequencing offer promising alternatives to DNA barcoding in the future. Despite the prevalence of DNA-based fungal taxonomy, phenotype-based approaches remain an important strategy to catalog the global diversity of fungi and establish initial species hypotheses}
}

@article{ShortenKhoshgoftaar.SurveyImageData.2019,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = {2019},
  month = jul,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.}
}

@incollection{Sobel.TaxonomyTrainingData.2021,
  title = {Taxonomy of {{Training Data}}: {{Disentangling}} the {{Mismatched Rights}}, {{Remedies}}, and {{Rationales}} for {{Restricting Machine Learning}}},
  booktitle = {Artificial {{Intelligence}} and {{Intellectual Property}}},
  author = {Sobel, Benjamin},
  editor = {Lee, Jyh-An and Hilty, Reto and Liu, Kung-Chung},
  year = {2021},
  month = feb,
  pages = {0},
  publisher = {Oxford University Press},
  doi = {10.1093/oso/9780198870944.003.0011},
  urldate = {2024-09-08},
  abstract = {Many machine learning applications depend on unauthorized uses of copyrighted training data. Scholars and lawmakers often articulate this problem as a deficiency in copyright's exceptions and limitations. In fact, today's predicament results not from inadequate exceptions to copyright, but rather from two systemic features of the regime---the absence of formalities and the low threshold of copyrightable originality---combined with technology that turns routine activities into acts of authorship. This chapter taxonomizes AI applications by their training data. Four categories emerge: (1) public-domain data, (2) licensed data, (3) market-encroaching uses of copyrighted data, and (4) non-market-encroaching uses of copyrighted data. Copyright can only regulate market-encroaching uses, but these uses comprise only a narrow subset of AI, and copyright's remedies are ill-suited to address them. The chapter concludes with a discussion of solutions to the problems it identifies. It observes that the exception for Text and Data Mining in the European Union's Directive on Copyright in the Digital Single Market represents a positive development because the exception addresses structural causes of AI's copyright problems. The TDM provision styles itself as an exception, but it may be better understood as a formality: rights holders must affirmatively reserve the right to exclude materials from training datasets. Thus, the TDM exception addresses a cause of AI's copyright dilemma. The next step for an equitable AI framework will be to transition towards rules that not only clarify that non-market-encroaching uses do not infringe copyright, but also facilitate remunerated uses of copyrighted works for market-encroaching purposes.},
  isbn = {978-0-19-887094-4}
}
